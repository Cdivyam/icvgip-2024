<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Explore the ICVGIP 2024 Call for Papers, a premier event for innovations in computer vision, graphics, and image processing, hosted by IIIT-Bangalore and IUPRAI. Engage with global experts, delve into groundbreaking research, and contribute to the advancement of these dynamic fields. Visit the website for submission details and guidelines.">
    <meta name="keywords"
        content="ICVGIP 2024, ICVGIP 2024 Call for papers, Computer Vision, Graphics, Image Processing">
    <meta property="og:title" content="ICVGIP 2024 | IIIT-Bangalore | Accepted Tiny Papers" />
    <meta property="og:description"
        content="Welcome to 15th Indian Conference on Vision Graphics and Image Processing - ICVGIP 2024 at IIIT-Bangalore" />
    <meta property="og:image" content="https://icvgip.in/assets/iiitb_cover3.jpg" />
    <title>ICVGIP 2024</title>
    <link rel="canonical" href="https://icvgip.in/accepted-tiny-papers">
    <link href="./index-output.css" rel="stylesheet">
    <link rel="icon" type="image/x-icon" href="assets/favico-v4.png">
</head>

<body class="bg-slate-200">
    <div class="container max-w-xl lg:max-w-4xl xl:max-w-6xl 2xl:max-w-7xl  mx-auto shadow-2xl">
        <!-- ===========================Header and navbar=========================== -->
        <header class="bg-white">
            <div class="w-full h-96 bg-iiitb-cover-3 bg-cover bg-center align-bottom relative">
                <div class="flex w-100 justify-end">
                    <div class="p-3 w-[90px] sm:w-[110px]">
                        <img src="assets/logos/iuprai-d_1.png" alt="IUPRAI LOGO">
                    </div>
                </div>
                <div class="text-white p-4 absolute bottom-0 ">
                    <div class="font-extrabold font-urbanist text-5xl text-shadow">ICVGIP 2024</div>
                    <div class="font-bold font-urbanist text-2xl text-shadow">IIIT-Bangalore | 13<sup>th</sup> to
                        15<sup>th</sup> December, 2024</div>
                </div>
            </div>
            <nav id="navbar"
                class="flex flex-col lg:flex-row items-center justify-start bg-navigationPurple-700 text-white text-xl border-t-2 border-white">
                <div id="hamburger-nav-menu"
                    class="w-full flex justify-center lg:hidden p-4 lg:px-6 hover:bg-navigationPurple-500 hover:cursor-pointer">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                        stroke="currentColor" class="w-6 h-6">
                        <path stroke-linecap="round" stroke-linejoin="round"
                            d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" />
                    </svg>
                </div>
                <div id="mobile-nav" class="hidden flex-col w-full lg:hidden items-center justify-center text-center">
                    <a class="w-full p-2 hover:bg-navigationPurple-500 hover:cursor-pointer" href="index.html"> Home </a>
                    <div id="subnav-program" class="w-full p-2 hover:bg-navigationPurple-500 hover:cursor-pointer">
                        Program
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" class="w-6 h-6 inline-block ml-2">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M19 9l-7 7-7-7"></path>
                        </svg>
                    </div>
                    <a class="subnav-program hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="program.html"> Conference Program </a>
                    <a class="subnav-program hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="tutorials.html"> Tutorials </a>
                    <a class="subnav-program hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="plenaryspeakers.html"> Plenary Speakers </a>
                    <a class="subnav-program hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="accepted-regular-papers.html"> Accepted Regular Papers </a>
                    <a class="subnav-program hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="accepted-symposium-papers.html"> Accepted Symposium Papers </a>
                    <a class="subnav-program hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="accepted-tiny-papers.html"> Accepted Tiny Papers </a>
                    <a class="subnav-program hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="vision-india-session.html"> VISION INDIA </a>
                    <div id="subnav-infoatt" class="w-full p-2 hover:bg-navigationPurple-500 hover:cursor-pointer">
                        Info For Attendees
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" class="w-6 h-6 inline-block ml-2">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M19 9l-7 7-7-7"></path>
                        </svg>
                    </div>
                    <a class="subnav-infoatt hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="travel.html"> Travel </a>
                    <a class="subnav-infoatt hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="registration.html"> Registration </a>
                    <a class="subnav-infoatt hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="accommodation.html"> Accommodation </a>
                    <a class="subnav-infoatt hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="venue.html"> Venue </a>
                    <div id="subnav-infoauth" class="w-full p-2 hover:bg-navigationPurple-500 hover:cursor-pointer">
                        Info For Authors
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"
                            class="w-6 h-6 inline-block ml-2">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M19 9l-7 7-7-7"></path>
                        </svg>
                    </div>
                    <a class="subnav-infoauth hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="instructions-for-presentations.html"> Presentation Instructions </a>
                    <a class="subnav-infoauth hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="iuprai-doctoral-dissertation-award.html"> IUPRAI Doctoral Dissertation Award </a>
                    <a class="subnav-infoauth hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="vision-india.html"> Vision INDIA </a>
                    <a class="subnav-infoauth hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="call-for-tutorials.html"> Call For Tutorials </a>
                    <a class="subnav-infoauth hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="call-for-tiny-papers.html"> Call For Tiny Papers </a>
                    <a class="subnav-infoauth hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="young-researcher-symposium.html">  Young Researchers' Symposium </a>
                    <a class="subnav-infoauth hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="young-faculty-symposium.html">  Young Faculty' Symposium </a>
                    <a class="subnav-infoauth hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="industry-research-symposium.html">  Industry Research Symposium </a>
                    <a class="subnav-infoauth hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="dates.html"> Important Dates </a>
                    <a class="subnav-infoauth hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="cfp.html"> Call For papers </a>
                    <a class="subnav-infoauth hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer" href="regular-paper-submission.html"> Regular Paper Submission </a>
                    <a class="w-full p-2 hover:bg-navigationPurple-500 hover:cursor-pointer" href="plenaryspeakers.html"> Plenary Speakers </a>
                    <div id="subnav-committees" class="w-full p-2 hover:bg-navigationPurple-500 hover:cursor-pointer">
                        Committees
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"
                            class="w-6 h-6 inline-block ml-2">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M19 9l-7 7-7-7"></path>
                        </svg>
                    </div>
                    <a class="subnav-committees hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer"
                        href="organisers.html"> Organising Committee </a>
                    <a class="subnav-committees hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer"
                        href="steering.html"> Steering Committee </a>
                    <a class="subnav-committees hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer"
                        href="plenarychair.html"> Plenary Chair </a>
                    
                    <a class="w-full p-2 hover:bg-navigationPurple-500 hover:cursor-pointer" href="call-for-bids.html">
                        BIDS </a>
                    <div id="subnav-archive" class="w-full p-2 hover:bg-navigationPurple-500 hover:cursor-pointer">
                        Archive
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"
                            class="w-6 h-6 inline-block ml-2">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M19 9l-7 7-7-7"></path>
                        </svg>
                    </div>
                    <a class="subnav-archive-year hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer"
                        href="https://www.iitrpr.ac.in/ICVGIP/" target="_blank"> 2023 </a>
                    <a class="subnav-archive-year hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer"
                        href="https://events.iitgn.ac.in/2022/icvgip/index.html" target="_blank"> 2022 </a>
                    <a class="subnav-archive-year hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer"
                        href="https://iitj.ac.in/icvgip2021/index.php" target="_blank"> 2021 </a>
                    <a class="subnav-archive-year hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer"
                        href="https://iitj.ac.in/icvgip2021/2020/index.php" target="_blank"> 2020 </a>
                    <a class="subnav-archive-year hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer"
                        href="https://cvit.iiit.ac.in/icvgip18/" target="_blank"> 2018 </a>
                    <a class="subnav-archive-year hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer"
                        href="https://dl.acm.org/doi/proceedings/10.1145/3009977" target="_blank"> 2016 </a>
                    <a class="subnav-archive-year hidden w-full p-2 bg-navigationPurple-500 hover:bg-navigationPurple-700 hover:cursor-pointer"
                        href="https://dl.acm.org/doi/proceedings/10.1145/2683483" target="_blank"> 2014 </a>
                </div>
                <a class="hidden lg:block p-4 lg:px-6 hover:bg-navigationPurple-500 hover:cursor-pointer " href="index.html">Home</a>
                <div class="hidden lg:block relative group p-4 lg:px-6 hover:bg-navigationPurple-500 hover:cursor-pointer border-l-2">
                    Program
                    <div class="absolute hidden group-hover:block bg-navigationPurple-700 shadow-md mt-4 w-[220%] z-10 left-0">
                        <a href="program.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Conference Program</a>
                        <a href="tutorials.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Tutorials</a>
                        <a href="plenaryspeakers.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Plenary Speakers</a>
                        <a href="accepted-regular-papers.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Accepted Regular Papers</a>
                        <a href="accepted-symposium-papers.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Accepted Symposium Papers</a>                        
                        <a href="accepted-tiny-papers.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Accepted Tiny Papers</a>
                        <a href="vision-india-session.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">VISION INDIA</a>
                    </div>
                </div>
                <div class="hidden lg:block relative group p-4 lg:px-6 hover:bg-navigationPurple-500 hover:cursor-pointer border-l-2">
                    Info For Attendees
                    <div class="absolute hidden group-hover:block bg-navigationPurple-700 shadow-md mt-4 w-[120%] z-10 left-0">
                        <a href="travel.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Travel</a>
                        <a href="registration.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Registration</a>
                        <a href="accommodation.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Accommodation</a>
                        <a href="venue.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Venue</a>
                    </div>
                </div>
                <div class="hidden lg:block relative group p-4 lg:px-6 hover:bg-navigationPurple-500 hover:cursor-pointer border-l-2">
                    Info For Authors
                    <div
                        class="absolute hidden group-hover:block bg-navigationPurple-700 shadow-md mt-4 w-[162%] z-10 left-0">
                        <a href="instructions-for-presentations.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Presentation Instructions</a>
                        <a href="iuprai-doctoral-dissertation-award.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">IUPRAI Doctoral Dissertation Award</a>
                        <a href="vision-india.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Vision INDIA</a>
                        <a href="call-for-tutorials.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Call For Tutorials</a>
                        <a href="call-for-tiny-papers.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Call For Tiny Papers</a>
                        <a href="young-researcher-symposium.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Young Researchers' Symposium</a>
                        <a href="young-faculty-symposium.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Young Faculty' Symposium</a>
                        <a href="industry-research-symposium.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Industry Research Symposium</a>
                        <a href="dates.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Important Dates</a>
                        <a href="cfp.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Call For papers</a>
                        <a href="regular-paper-submission.html" class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">Regular Paper Submission</a>
                    </div>
                </div>
                <a class="hidden lg:block p-4 lg:px-6 hover:bg-navigationPurple-500 hover:cursor-pointer border-l-2" href="plenaryspeakers.html">Plenary Speakers</a>
                <div
                    class="hidden lg:block relative group p-4 lg:px-6 hover:bg-navigationPurple-500 hover:cursor-pointer border-l-2">
                    Committees
                    <div
                        class="absolute hidden group-hover:block bg-navigationPurple-700 shadow-md mt-4 w-[155%] z-10 left-0">
                        <a href="organisers.html"
                            class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">
                            Organising Committee</a>
                        <a href="steering.html"
                            class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">
                            Steering Committee</a>
                        <a href="plenarychair.html"
                            class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">
                            Plenary Chair</a>
                    </div>
                </div>
                
                
                <a class="hidden lg:block p-4 lg:px-6 hover:bg-navigationPurple-500 hover:cursor-pointer border-l-2"
                    href="call-for-bids.html">BIDS</a>
                <div
                    class="hidden lg:block relative group p-4 lg:px-6 hover:bg-navigationPurple-500 hover:cursor-pointer border-x-2">
                    Archive
                    <div
                        class="absolute hidden group-hover:block bg-navigationPurple-700 shadow-md mt-4 w-full z-10 left-0">
                        <a href="https://www.iitrpr.ac.in/ICVGIP/" target="_blank"
                            class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">2023</a>
                        <a href="https://events.iitgn.ac.in/2022/icvgip/index.html" target="_blank"
                            class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">2022</a>
                        <a href="https://iitj.ac.in/icvgip2021/index.php" target="_blank"
                            class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">2021</a>
                        <a href="https://iitj.ac.in/icvgip2021/2020/index.php" target="_blank"
                            class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">2020</a>
                        <a href="https://cvit.iiit.ac.in/icvgip18/" target="_blank"
                            class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">2018</a>
                        <a href="https://dl.acm.org/doi/proceedings/10.1145/3009977" target="_blank"
                            class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">2016</a>
                        <a href="https://dl.acm.org/doi/proceedings/10.1145/2683483" target="_blank"
                            class="block p-4 text-white hover:bg-navigationPurple-500 border-y-white border-t-2">2014</a>
                    </div>
                </div>
                <!-- <div
                    class="hidden lg:flex items-center justify-evenly p-4 lg:px-6 gap-x-2 hover:bg-navigationPurple-500 hover:cursor-pointer
                            border-x-2">
                    Text
                    <svg class="h-5 w-5 flex-none text-gray-400" viewBox="0 0 20 20" fill="currentColor"
                        aria-hidden="true">
                        <path fill-rule="evenodd"
                            d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
                            clip-rule="evenodd" />
                    </svg>
                </div> -->
                <!-- <a class="lg:block p-4 lg:px-6 hover:bg-navigationPurple-400 hover:cursor-pointer text-navigationPurple-700">
                </a> -->
                <!-- <div class="p-6 lg:px-6">Test</div>
                 -->
            </nav>
        </header>

        <!-- ====================================================== -->
        <!-- Content -->
        <div class="flex flex-col bg-white lg:px-16">
            <div class="flex flex-col">
                <div class="text-4xl p-6">Accepted Tiny Papers</div>
                <hr class="h-px mx-5 bg-slate-400 border-0">
                <div class="text-md px-6 pt-4 text-justify">
                    <p>
                        We're thrilled to present the First Edition of Tiny Papers - a collection of concise, impactful ideas that push the boundaries of innovation. 
                        These short but powerful contributions offer fresh perspectives, novel insights, and spark discussions that shape the future of our discipline.
                        <br>
                        <br>
                        The list doubles as a Detailed Technical Program so Authors will know which time slot their
                        presentation is according to the <a href="program.html" target="_blank" class="text-blue-500">Conference Program.</a>
                        <br>
                        For list of Accepted Regular Papers jump <a href="accepted-regular-papers.html" target="_blank" class="text-blue-500">here.</a>
                        <br>
                        For list of Accepted Symposium Papers jump <a href="accepted-symposium-papers.html" target="_blank" class="text-blue-500">here.</a>
                        <br>
                        For list of Vision India Session Papers jump <a href="vision-india-session.html" target="_blank" class="text-blue-500">here.</a>
                    </p>
                </div>

                <div class="tiny-papers">
                    <div class="tiny-papers-showcase flex flex-col lg:flex-row lg:flex-wrap items-center lg:items-start w-full p-2 lg:p-5">
                        <div class="lg:w-1/2 xl:w-1/3 px-1 py-1">
                            <div class="border pb-3">
                                <!-- <div class="flex w-[80%] sm:w-1/2 md:w-[250px] justify-center">
                                    <img src="assets/AlBovik.jpg" alt="Alan Bovik">
                                </div> -->
                                <div class="w-full flex flex-col p-2 lg:px-5 lg:py-0">
                                    <div class="grid place-content-center font-urbanist text-xl font-bold text-center text-navigationPurple-700 py-2 h-[100px]">
                                        Deep Priors for Video Quality Prediction
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-speakers py-1 flex flex-col items-center">
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Siddharath Narayan Shakya</span>
                                            <span class="italic">, IIT Mandi</span>
                                        </div>
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Parimala Kancharla</span>
                                            <span class="italic">, IIT Mandi</span>
                                        </div>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-time py-1 text-center text-slate-500">
                                        <a href="https://arxiv.org/abs/2410.22566" target="_blank">
                                            <div class="text-sm lg:text-left flex justify-center">
                                                <img src="assets/logos/arxiv.png" alt="arxiv logo" width="20" height="20">
                                                <span>Arxiv</span>
                                            </div>
                                        </a>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="text-sm text-justify px-3 py-2 lg:px-0 pb-6 h-56 overflow-y-scroll">
                                        <p><strong>Abstract:</strong> In this work, we designed a completely blind video quality assessment algorithm using 
                                            the deep video prior. This work mainly explores the utility of deep video prior in estimating the visual quality 
                                            of the video. In our work, we have used a single distorted video and a reference video pair to learn the deep video 
                                            prior. At inference time, the learned deep prior is used to restore the original videos from the distorted videos. 
                                            The ability of learned deep video prior to restore the original video from the distorted video is measured to 
                                            quantify distortion in the video. Our hypothesis is that the learned deep video prior fails in restoring the 
                                            highly distorted videos. The restoring ability of deep video prior is proportional to the distortion present 
                                            in the video. Therefore, we propose to use the distance between the distorted video and the restored video as 
                                            the perceptual quality of the video. Our algorithm is trained using a single video pair and it does not need any 
                                            labelled data. We show that our proposed algorithm outperforms the existing unsupervised video quality assessment 
                                            algorithms in terms of LCC and SROCC on a synthetically distorted video quality assessment dataset. 
                                        </p>
                                    </div>                 
                                </div>
                            </div>
                        </div>
                        <div class="lg:w-1/2 xl:w-1/3 px-1 py-1">
                            <div class="border pb-3">
                                <!-- <div class="flex w-[80%] sm:w-1/2 md:w-[250px] justify-center">
                                    <img src="assets/AlBovik.jpg" alt="Alan Bovik">
                                </div> -->
                                <div class="w-full flex flex-col p-2 lg:px-5 lg:py-0">
                                    <div class="grid place-content-center font-urbanist text-lg font-bold text-center text-navigationPurple-700 py-2 h-[100px]">
                                        Temporal and Spatial Super Resolution with Latent Diffusion Model in Medical MRI images
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-speakers py-1 flex flex-col items-center">
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Vishal Dubey</span>
                                        </div>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-time py-1 text-center text-slate-500">
                                        <a href="https://arxiv.org/abs/2410.23898" target="_blank">
                                            <div class="text-sm lg:text-left flex justify-center">
                                                <img src="assets/logos/arxiv.png" alt="arxiv logo" width="20" height="20">
                                                <span>Arxiv</span>
                                            </div>
                                        </a>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="text-sm text-justify px-3 py-2 lg:px-0 pb-6 h-56 overflow-y-scroll">
                                        <p><strong>Abstract:</strong> Super Resolution (SR) plays a critical role in computer vision, particularly in medical
                                            imaging, where hardware and acquisition time constraints often result in low spatial and temporal resolution. While
                                            diffusion models have been applied for both spatial and temporal SR, few studies have explored their use for joint
                                            spatial and temporal SR, particularly in medical imaging. In this work, we address this gap by proposing to use a
                                            Latent Diffusion Model (LDM) combined with a Vector Quantised GAN (VQGAN)-based encoder-decoder architecture for
                                            joint super resolution. We frame SR as an image denoising problem, focusing on improving both spatial and temporal
                                            resolution in medical images. Using the cardiac MRI dataset from the Data Science Bowl Cardiac Challenge, consisting
                                            of 2D cine images with a spatial resolution of 256x256 and 8-14 slices per time-step, we demonstrate the
                                            effectiveness of our approach. Our LDM model achieves Peak Signal to Noise Ratio (PSNR) of 30.37, Structural
                                            Similarity Index (SSIM) of 0.7580, and Learned Perceptual Image Patch Similarity (LPIPS) of 0.2756, outperforming
                                            simple baseline method by 5% in PSNR, 6.5% in SSIM, 39% in LPIPS. Our LDM model generates images with high fidelity
                                            and perceptual quality with 15 diffusion steps. These results suggest that LDMs hold promise for advancing super
                                            resolution in medical imaging, potentially enhancing diagnostic accuracy and patient outcomes. Code link is also
                                            shared.
                                        </p>
                                    </div>                 
                                </div>
                            </div> 
                        </div> 
                        <div class="lg:w-1/2 xl:w-1/3 px-1 py-1">
                            <div class="border pb-3">
                                <!-- <div class="flex w-[80%] sm:w-1/2 md:w-[250px] justify-center">
                                    <img src="assets/AlBovik.jpg" alt="Alan Bovik">
                                </div> -->
                                <div class="w-full flex flex-col p-2 lg:px-5 lg:py-0">
                                    <div class="grid place-content-center font-urbanist text-xl font-bold text-center text-navigationPurple-700 py-2 h-[100px]">
                                        Image Generation from Image Captioning - Invertible Approach
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-speakers py-1 flex flex-col items-center">
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Raghuram Diddigi</span>
                                            <span class="italic">, IIIT-Bangalore</span>
                                        </div>
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Menon Nandakishore</span>
                                            <span class="italic">, IBM Rsch, Bangalore</span>
                                        </div>
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Kamanchi Chandramouli</span>
                                            <span class="italic">, IBM Rsch, Bangalore</span>
                                        </div>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-time py-1 text-center text-slate-500">
                                        <a href="https://arxiv.org/abs/2410.20171" target="_blank">
                                            <div class="text-sm lg:text-left flex justify-center">
                                                <img src="assets/logos/arxiv.png" alt="arxiv logo" width="20" height="20">
                                                <span>Arxiv</span>
                                            </div>
                                        </a>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="text-sm text-justify px-3 py-2 lg:px-0 pb-6 h-56 overflow-y-scroll">
                                        <p><strong>Abstract:</strong> Our work aims to build a model that performs dual tasks of image captioning and image
                                            generation while being trained on only one task. The central idea is to train an invertible model that learns a
                                            one-to-one mapping between the image and text embeddings. Once the invertible model is efficiently trained on one
                                            task, the image captioning, the same model can generate new images for a given text through the inversion process,
                                            with no additional training. This paper proposes a simple invertible neural network architecture for this problem
                                            and presents our current findings.
                                        </p>
                                    </div>                 
                                </div>
                            </div> 
                        </div>
                        
                    </div>
                    <div class="tiny-papers-showcase flex flex-col lg:flex-row lg:flex-wrap items-center lg:items-start w-full p-2 lg:px-5 lg:pt-2">
                        <div class="lg:w-1/2 xl:w-1/3 px-1 py-1">
                            <div class="border pb-3">
                                <!-- <div class="flex w-[80%] sm:w-1/2 md:w-[250px] justify-center">
                                    <img src="assets/AlBovik.jpg" alt="Alan Bovik">
                                </div> -->
                                <div class="w-full flex flex-col p-2 lg:px-5 lg:py-0">
                                    <div class="grid place-content-center font-urbanist text-xl font-bold text-center text-navigationPurple-700 py-2 h-[100px]">
                                        Defective Edge Detection Using Cascaded Ensemble Canny Operator
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-speakers py-1 flex flex-col items-center">
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Anjali Nambiyar</span>
                                            <span class="italic">, Bishop Heber College</span>
                                        </div>
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Rajkumar Kannan</span>
                                            <span class="italic">, Bishop Heber College</span>
                                        </div>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-time py-1 text-center text-slate-500">
                                        <a href="https://arxiv.org/abs/2411.14868" target="_blank">
                                            <div class="text-sm lg:text-left flex justify-center">
                                                <img src="assets/logos/arxiv.png" alt="arxiv logo" width="20" height="20">
                                                <span>Arxiv</span>
                                            </div>
                                        </a>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="text-sm text-justify px-3 py-2 lg:px-0 pb-6 h-56 overflow-y-scroll">
                                        <p><strong>Abstract:</strong> Edge detection has been one of the most difficult challenges in computer vision because of
                                            the difficulty in identifying the borders and edges from the real-world images including objects of varying kinds
                                            and sizes. Methods based on ensemble learning, which use a combination of backbones and attention modules,
                                            outperformed more conventional approaches, such as Sobel and Canny edge detection. Nevertheless, these algorithms
                                            are still challenged when faced with complicated scene photos. In addition, the identified edges utilizing the
                                            current methods are not refined and often include incorrect edges. In this work, we used a Cascaded Ensemble Canny
                                            operator to solve these problems and detect the object edges. The most difficult Fresh and Rotten and Berkeley
                                            datasets are used to test the suggested approach in Python. In terms of performance metrics and output picture
                                            quality, the acquired results outperform the specified edge detection networks.
                                        </p>
                                    </div>                 
                                </div>
                            </div> 
                        </div>
                        <div class="lg:w-1/2 xl:w-1/3 px-1 py-1">
                            <div class="border pb-3">
                                <!-- <div class="flex w-[80%] sm:w-1/2 md:w-[250px] justify-center">
                                    <img src="assets/AlBovik.jpg" alt="Alan Bovik">
                                </div> -->
                                <div class="w-full flex flex-col p-2 lg:px-5 lg:py-0">
                                    <div class="grid place-content-center font-urbanist text-xl font-bold text-center text-navigationPurple-700 py-2 h-[100px]">
                                        WavShadow: Wavelet Based Shadow Segmentation and Removal
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-speakers py-1 flex flex-col items-center">
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Shreyans Jain</span>
                                            <span class="italic">, IIT Gandhinagar</span>
                                        </div>
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Viraj Vekaria</span>
                                            <span class="italic">, IIT Gandhinagar</span>
                                        </div>
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Karan Sagar Gandhi</span>
                                            <span class="italic">, IIT Gandhinagar</span>
                                        </div>
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Aadya Arora</span>
                                            <span class="italic">, IIT Gandhinagar</span>
                                        </div>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-time py-1 text-center text-slate-500">
                                        <a href="https://arxiv.org/abs/2411.05747" target="_blank">
                                            <div class="text-sm lg:text-left flex justify-center">
                                                <img src="assets/logos/arxiv.png" alt="arxiv logo" width="20" height="20">
                                                <span>Arxiv</span>
                                            </div>
                                        </a>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="text-sm text-justify px-3 py-2 lg:px-0 pb-6 h-56 overflow-y-scroll">
                                        <p><strong>Abstract:</strong> Shadow removal and segmentation remain challenging tasks in computer vision, particularly
                                            in complex real world scenarios. This study presents a novel approach that enhances the ShadowFormer model by
                                            incorporating Masked Autoencoder (MAE) priors and Fast Fourier Convolution (FFC) blocks, leading to significantly
                                            faster convergence and improved performance. We introduce key innovations: (1) integration of MAE priors trained on
                                            Places2 dataset for better context understanding, (2) adoption of Haar wavelet features for enhanced edge detection
                                            and multiscale analysis, and (3) implementation of a modified SAM Adapter for robust shadow segmentation. Extensive
                                            experiments on the challenging DESOBA dataset demonstrate that our approach achieves state of the art results, with
                                            notable improvements in both convergence speed and shadow removal quality.
                                        </p>
                                    </div>                 
                                </div>
                            </div> 
                        </div>
                        <div class="lg:w-1/2 xl:w-1/3 px-1 py-1">
                            <div class="border pb-3">
                                <!-- <div class="flex w-[80%] sm:w-1/2 md:w-[250px] justify-center">
                                    <img src="assets/AlBovik.jpg" alt="Alan Bovik">
                                </div> -->
                                <div class="w-full flex flex-col p-2 lg:px-5 lg:py-0">
                                    <div class="grid place-content-center font-urbanist text-xl font-bold text-center text-navigationPurple-700 py-2 h-[100px]">
                                        Adaptive Multi Scale Document Binarisation Using Vision Mamba
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-speakers py-1 flex flex-col items-center">
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Siddhant Bharadwaj</span>
                                            <span class="italic">, IISc Bangalore</span>
                                        </div>
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Mohd Azfar</span>
                                            <span class="italic">, IISc Bangalore</span>
                                        </div>
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Ashwin Sasikumar</span>
                                            <span class="italic">, IIIT-Bangalore</span>
                                        </div>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-time py-1 text-center text-slate-500">
                                        <a href="https://arxiv.org/abs/2410.22811" target="_blank">
                                            <div class="text-sm lg:text-left flex justify-center">
                                                <img src="assets/logos/arxiv.png" alt="arxiv logo" width="20" height="20">
                                                <span>Arxiv</span>
                                            </div>
                                        </a>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="text-sm text-justify px-3 py-2 lg:px-0 pb-6 h-56 overflow-y-scroll">
                                        <p><strong>Abstract:</strong> Enhancing and preserving the readability of document images, particularly historical ones,
                                            is crucial for effective document image analysis. Numerous models have been proposed for this task, including
                                            convolutional-based, transformer-based, and hybrid convolutional-transformer architectures. While hybrid models
                                            address the limitations of purely convolutional or transformer-based methods, they often suffer from issues like
                                            quadratic time complexity. In this work, we propose a Mamba-based architecture for document binarisation, which
                                            efficiently handles long sequences by scaling linearly and optimizing memory usage. Additionally, we introduce novel
                                            modifications to the skip connections by incorporating Difference of Gaussians (DoG) features, inspired by
                                            conventional signal processing techniques. These multiscale high-frequency features enable the model to produce
                                            high-quality, detailed outputs.
                                        </p>
                                    </div>                 
                                </div>
                            </div> 
                        </div>                    
                    </div>
                    <div class="tiny-papers-showcase flex flex-col lg:flex-row lg:flex-wrap items-center lg:items-center justify-center w-full p-2 lg:px-5 lg:pt-2 pb-4">
                        <div class="lg:w-1/2 xl:w-1/3 px-1 py-1">
                            <div class="border pb-3">
                                <!-- <div class="flex w-[80%] sm:w-1/2 md:w-[250px] justify-center">
                                    <img src="assets/AlBovik.jpg" alt="Alan Bovik">
                                </div> -->
                                <div class="w-full flex flex-col p-2 lg:px-5 lg:py-0">
                                    <div class="grid place-content-center font-urbanist text-lg font-bold text-center text-navigationPurple-700 py-2 h-[120px]">
                                        Practical and Accurate Reconstruction of an Illuminant's Spectral Power Distribution for Inverse Rendering Pipelines
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-speakers py-1 flex flex-col items-center">
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Parisha Joshi</span>
                                            <span class="italic">, Clemson University</span>
                                        </div>
                                        <div class="text-sm text-center lg:text-left">
                                            <span class="font-bold">Daljit Singh Dhillon</span>
                                            <span class="italic">, Clemson University</span>
                                        </div>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="tutorial-time py-1 text-center text-slate-500">
                                        <a href="https://arxiv.org/abs/2410.22679" target="_blank">
                                            <div class="text-sm lg:text-left flex justify-center">
                                                <img src="assets/logos/arxiv.png" alt="arxiv logo" width="20" height="20">
                                                <span>Arxiv</span>
                                            </div>
                                        </a>
                                    </div>
                                    <hr class="h-px bg-slate-400 border-0">
                                    <div class="text-sm text-justify px-3 py-2 lg:px-0 pb-6 h-56 overflow-y-scroll">
                                        <p><strong>Abstract:</strong> Inverse rendering pipelines are gaining prominence in realizing photo-realistic
                                            reconstruction of real-world objects for emulating them in virtual reality scenes. Apart from material reflectances,
                                            spectral rendering and in-scene illuminants' spectral power distributions (SPDs) play important roles in producing
                                            photo-realistic images. We present a simple, low-cost technique to capture and reconstruct the SPD of uniform
                                            illuminants. Instead of requiring a costly spectrometer for such measurements, our method uses a diffractive compact
                                            disk (CD-ROM) and a machine learning approach for accurate estimation. We show our method to work well with
                                            spotlights under simulations and few real-world examples. Presented results clearly demonstrate the reliability of
                                            our approach through quantitative and qualitative evaluations, especially in spectral rendering of iridescent
                                            materials.
                                        </p>
                                    </div>                 
                                </div>
                            </div> 
                        </div>
                        
                    </div>
                </div>

                <!-- <div class="text-md px-6 pb-4">
                    Note: The data shown was received and put as is. For spelling errors, you may fill the following form:
                    <div class="flex flex-col w-full min-[480px]:w-4/5 lg:w-1/2 xl:w-1/3 mt-4">
                        <div class="bg-navigationPurple-700 p-2 text-white"> Young Faculty Symposium Track Chair</div>
                        <div class="text-sm bg-slate-50 p-2">
                            <ul>
                                <li>Dr. Neelam Sinha (IISc) </li>
                                <li><a class="text-blue-500"
                                        href="mailto:neelam@cbr-iisc.ac.in">neelam@cbr-iisc.ac.in</a>
                                </li>
                            </ul>
                        </div>
                    </div>
                </div> -->

            </div>
            <!-- <div class="w-full xl:w-5/6">
                <iframe 
                    src="https://docs.google.com/document/d/e/2PACX-1vQ17DK2F-qH1hdwG-oNnkV7AuEf5mOjBUVIYqBg1b68TiWJS3vKOj92D5gELxzAsQ34cI4JlWIRKls_/pub?embedded=true" 
                    id="google-doc-iframe" frameborder="0" name="google-doc-iframe" width="100%" height="1336px" onload="resizeIframe(this)">
                </iframe>
            </div> -->
        </div>

        <footer class="bg-navigationPurple-700">
            <div
                class="flex flex-col lg:flex-row text-white items-center lg:items-start lg:justify-between p-3 lg:p-10">
                <div class="w-1/3 order-1 lg:order-2 flex justify-center">
                    <img width="276px" src="assets/logo.svg" alt="icvgip-logo">
                </div>
                <div
                    class="w-full lg:w-1/3 flex flex-col order-3 items-center lg:items-start text-center lg:text-left lg:order-1 px-16 pt-5 lg:px-0 lg:pt-0 text-sm">
                    <div class="pb-2">Institute Address</div>
                    <div class="w-2/3 h-[1px] bg-white"></div>
                    <div class="pt-2 lg:w-2/3 ">26/C, Opposite of Infosys gate 10, Electronics City Phase 1, Hosur Road,
                        Bengaluru - 560100</div>
                </div>
                <div id="socials"
                    class="flex flex-col w-1/3 order-2 items-center justify-center lg:items-end lg:order-3 pt-5 lg:pt-0">
                    <div class="hidden lg:block pb-2 text-sm">Socials</div>
                    <div class="w-2/3 lg:w-1/3 h-[1px] bg-white"></div>
                    <div class="flex flex-row w-full justify-center lg:justify-end gap-2 pt-5 lg:pt-2">
                        <a class="text-white hover:text-blue-400" aria-label="LinkedIn" href="" target="_blank">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="h-4">
                                <path fill="currentColor"
                                    d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z">
                                </path>
                            </svg>
                        </a>
                        <a class="text-white hover:text-black" aria-label="X" href="" target="_blank">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 30 30" class="h-4">
                                <path fill="currentColor"
                                    d="M26.37,26l-8.795-12.822l0.015,0.012L25.52,4h-2.65l-6.46,7.48L11.28,4H4.33l8.211,11.971L12.54,15.97L3.88,26h2.65 l7.182-8.322L19.42,26H26.37z M10.23,6l12.34,18h-2.1L8.12,6H10.23z">
                                </path>
                            </svg>
                        </a>
                    </div>

                </div>

            </div>
            <div id="copyright" class="text-white text-center text-xs p-2">
                © 2024 IIIT-Bangalore. All Rights Reserved.
            </div>
        </footer>
    </div>
    <!--  -->

    <!-- <div class="bg-slate-400 container-sm mx-auto h-10">

    </div> -->
    <script src="index.js"></script>
    <!-- <script>
        function resizeIframe(obj) {
            obj.style.height = obj.contentWindow.document.documentElement.scrollHeight + 'px';
        }
     </script> -->
    <script>
        function resizeIframe(obj) {
            let screen_width = screen.width
            console.log(screen_width)
            if (screen_width <= 1536) {
                obj.height = '1336px'
            }
            if (screen_width <= 1280) {
                obj.height = '1336px'
            }
            if (screen_width <= 1024) {
                obj.height = '1650px'
            }
            if (screen_width <= 768) {
                obj.height = '1650px'
            }
            if (screen_width <= 640) {
                obj.height = '2600px'
            }

        }
        // var iframe = document.getElementById("google-doc-iframe");
    </script>

</body>

</html>